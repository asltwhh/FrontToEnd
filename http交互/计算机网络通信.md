# 计算机网络知识总结

本部分主要是笔者在复习计算机网络相关知识和一些相关面试题时所做的笔记，如果出现错误，希望大家指出！

## 目录

- 应用层
  - HTTP 协议
    - [概况](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#概况)
    - [HTTP 请求报文](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#http-请求报文)
    - [HTTP 响应报文](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#http-响应报文)
    - [首部行](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#首部行)
    - [HTTP/1.1 协议缺点](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#http11-协议缺点)
  - HTTP/2 协议
    - [二进制协议](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#二进制协议)
    - [多路复用](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#多路复用)
    - [数据流](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#数据流)
    - [头信息压缩](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#头信息压缩)
    - [服务器推送](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#服务器推送)
    - [HTTP/2 协议缺点](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#http2-协议缺点)
    - [HTTP/3 协议](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#http3-协议)
  - HTTPS 协议
    - [HTTP 存在的问题](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#http-存在的问题)
    - [HTTPS 简介](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#https-简介)
    - [TLS 握手过程](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#tls-握手过程)
    - [实现原理](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#实现原理)
  - DNS 协议
    - [概况](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#概况-1)
    - [域名的层级结构](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#域名的层级结构)
    - [查询过程](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#查询过程)
    - [DNS 记录和报文](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#dns-记录和报文)
    - [递归查询和迭代查询](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#递归查询和迭代查询)
    - [DNS 缓存](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#dns-缓存)
    - [DNS 实现负载平衡](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#dns-实现负载平衡)
- 传输层
  - [多路复用与多路分解](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#多路复用与多路分解)
  - UDP 协议
    - [UDP 报文段结构](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#udp-报文段结构)
  - TCP 协议
    - [TCP 报文段结构](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#tcp-报文段结构)
    - [TCP 三次握手的过程](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#tcp-三次握手的过程)
    - [TCP 四次挥手的过程](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#tcp-四次挥手的过程)
    - [状态转化图](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#状态转化图)
    - [ARQ 协议](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#arq-协议)
    - [TCP 的可靠运输机制](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#tcp-的可靠运输机制)
    - [TCP 的流量控制机制](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#tcp-的流量控制机制)
    - [TCP 的拥塞控制机制](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#tcp-的拥塞控制机制)
  - [网络层](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#网络层)
  - [数据链路层](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#数据链路层)
  - [物理层](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#物理层)
- 常考面试题
  - [1. Post 和 Get 的区别？](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#1-post-和-get-的区别)
  - [2. TLS/SSL 中什么一定要用三个随机数，来生成"会话密钥"？](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#2-tlsssl-中什么一定要用三个随机数来生成会话密钥)
  - [3. SSL 连接断开后如何恢复？](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#3-ssl-连接断开后如何恢复)
  - [4. RSA 算法的安全性保障？](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#4-rsa-算法的安全性保障)
  - [5. DNS 为什么使用 UDP 协议作为传输层协议？](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#5-dns-为什么使用-udp-协议作为传输层协议)
  - [6. 当你在浏览器中输入 Google.com 并且按下回车之后发生了什么？](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#6-当你在浏览器中输入-googlecom-并且按下回车之后发生了什么)
  - [7. 谈谈 CDN 服务？](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#7-谈谈-cdn-服务)
  - [8. 什么是正向代理和反向代理？](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#8-什么是正向代理和反向代理)
  - [9. 负载平衡的两种实现方式？](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#9-负载平衡的两种实现方式)
  - [10. http 请求方法 options 方法有什么用？](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#10-http-请求方法-options-方法有什么用)
  - [11. http1.1 和 http1.0 之间有哪些区别？](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#11-http11-和-http10-之间有哪些区别)
  - [12. 网站域名加 www 与不加 www 的区别？](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#12-网站域名加-www-与不加-www-的区别)
  - [13. 即时通讯的实现，短轮询、长轮询、SSE 和 WebSocket 间的区别？](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#13-即时通讯的实现短轮询长轮询sse-和-websocket-间的区别)
  - [14. 怎么实现多个网站之间共享登录状态](https://github.com/CavsZhouyou/Front-End-Interview-Notebook/blob/master/计算机网络/计算机网络.md#14-怎么实现多个网站之间共享登录状态)

TCP: Transport Control Protocol   传输控制协议

UDP：User Datagram Protocol 用户数据报协议

HTTP: HyperText Transport Protocol   超文本传输协议

HTTPS: Hyper Text Transfer Protocol over SecureSocket Layer  以安全为目标的 HTTP 通道

SSL:  Secure Socket Layer  安全套接字协议

TLS: Transport Layer Secure 安全传输层协议

DNS： Domain Name System  域名系统

ARQ: Automatic Repeat-reQuest 自动重传协议

CDN： Content Delivery Network 内容分发网络

## 1 应用层

应用层协议定义了应用进程间的交互和通信规则，不同主机的应用进程间如何相互传递报文，比如传递的报文的类型、格式、 有哪些字段等等。

### 1.1 HTTP 协议

HTTP 是超文本传输协议，它定义了客户端和服务器之间交换报文的格式和方式，默认使用 80 端口。它使用 TCP 作为传 输层协议，保证了数据传输的可靠性。

HTTP 是一个无状态的协议，HTTP 服务器不会保存关于客户的任何信息。

HTTP 有两种连接模式，一种是持续连接，一种非持续连接。非持续连接指的是服务器必须为每一个请求的对象建立和维护 一个全新的连接。持续连接下，TCP 连接默认不关闭，可以被多个请求复用。采用持续连接的好处是可以避免每次建立 TCP 连接三次握手时所花费的时间。在 HTTP1.0 以前使用的非持续的连接，但是可以在请求时，加上 Connection: keep-a live 来要求服务器不要关闭 TCP 连接。HTTP1.1 以后默认采用的是持续的连接。目前对于同一个域，大多数浏览器支持 同时建立 6 个持久连接。

#### 1.1.1 HTTP 请求报文

HTTP 报文有两种，一种是请求报文，一种是响应报文。

HTTP 请求报文的格式如下：

```
GET / HTTP/1.1
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5)
Accept: */*
```

HTTP 请求报文的第一行叫做请求行，后面的行叫做首部行，首部行后还可以跟一个实体主体。请求首部之后有一个空行，这 个空行不能省略，它用来划分首部与实体。

请求行包含三个字段：方法字段、URL 字段和 HTTP 版本字段。

方法字段可以取几种不同的值，一般有 GET、POST、HEAD、PUT 和 DELETE。一般 GET 方法只被用于向服务器获取数据。 POST 方法用于将实体提交到指定的资源，通常会造成服务器资源的修改。HEAD 方法与 GET 方法类似，但是在返回的响应 中，不包含请求对象。PUT 方法用于上传文件到服务器，DELETE 方法用于删除服务器上的对象。虽然请求的方法很多，但 更多表达的是一种语义上的区别，并不是说 POST 能做的事情，GET 就不能做了，主要看我们如何选择。更多的方法可以参 看[文档](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Methods)。

#### 1.1.2 HTTP 响应报文

HTTP 报文有两种，一种是请求报文，一种是响应报文。

HTTP 响应报文的格式如下：

```
HTTP/1.0 200 OK
Content-Type: text/plain
Content-Length: 137582
Expires: Thu, 05 Dec 1997 16:00:00 GMT
Last-Modified: Wed, 5 August 1996 15:55:28 GMT
Server: Apache 0.84

<html>
  <body>Hello World</body>
</html>
```

HTTP 响应报文的第一行叫做状态行，后面的行是首部行，最后是实体主体。

状态行包含了三个字段：协议版本字段、状态码和相应的状态信息。

实体部分是报文的主要部分，它包含了所请求的对象。

常见的状态有

200-请求成功、202-服务器端已经收到请求消息，但是尚未进行处理 301-永久移动、302-临时移动、304-所请求的资源未修改、 400-客户端请求的语法错误、404-请求的资源不存在 500-服务器内部错误。

一般 1XX 代表服务器接收到请求、2XX 代表成功、3XX 代表重定向、4XX 代表客户端错误、5XX 代表服务器端错误。

更多关于状态码的可以查看：

[《HTTP 状态码》](http://www.runoob.com/http/http-status-codes.html)

#### 1.1.3 首部行

首部可以分为四种首部，请求首部、响应首部、通用首部和实体首部。通用首部和实体首部在请求报文和响应报文中都可以设 置，区别在于请求首部和响应首部。

常见的请求首部有 Accept 可接收媒体资源的类型、Accept-Charset 可接收的字符集、Host 请求的主机名。

常见的响应首部有 ETag 资源的匹配信息，Location 客户端重定向的 URI。

常见的通用首部有 Cache-Control 控制缓存策略、Connection 管理持久连接。

常见的实体首部有 Content-Length 实体主体的大小、Expires 实体主体的过期时间、Last-Modified 资源的最后修 改时间。

更多关于首部的资料可以查看：

[《HTTP 首部字段详细介绍》](https://www.cnblogs.com/jycboy/p/http_head.html)

[《图解 HTTP》](https://blog.csdn.net/qq_34289537/article/details/52971516)

#### 1.1.4 http协议版本对比

##### 1. HTTP1.0协议存在的问题：

- http1.0默认采用短连接，短连接指的是tcp,即发送一次http请求，就需要进行一次tcp连接。浏览器最快也要在第三次握手时才能捎带 HTTP 请求报文，达到真正的建立连接，但是这些连接无法复用会导致每次请求都经历三次握手和慢启动。三次握手在高延迟的场景下影响较明显，慢启动则对文件类大请求影响较大。

##### 2.  HTTP1.0和HTTP1.1的区别：

- **缓存处理**，在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。
- **带宽优化及网络连接的使用**，HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。
- **错误通知的管理**，在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。
- **Host头处理**，在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）。
- **长连接**，HTTP 1.1支持长连接（PersistentConnection）和请求的流水线（Pipelining）处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟，在HTTP1.1中默认开启Connection： keep-alive，一定程度上弥补了HTTP1.0每次请求都要创建连接的缺点。

##### 3. HTTP/1.1 协议缺点

- HTTP/1.1 默认使用了持久连接，多个请求可以复用同一个 TCP 连接，但是在同一个 TCP 连接里面，数据请求的通信次序 是固定的,即多个请求是串行发送的。服务器只有处理完一个请求的响应后，才会进行下一个请求的处理，如果前面请求的响应特别慢的话，就会造成许 多请求排队等待的情况，这种情况被称为“队头堵塞”。队头阻塞会导致持久连接在达到最大数量时，剩余的资源需要等待其他 资源请求完成后才能发起请求。

- 为了避免这个问题，一个是减少请求数，一个是同时打开多个持久连接。这就是我们对网站优化时，使用雪碧图、合并脚本的 原因。

##### 4. HTTP/2 协议

2009 年，谷歌公开了自行研发的 SPDY 协议，主要解决 HTTP/1.1 效率不高的问题。这个协议在 Chrome 浏览器上证明 可行以后，就被当作 HTTP/2 的基础，主要特性都在 HTTP/2 之中得到继承。2015 年，HTTP/2 发布。

**http SPDY tsl TCP**

HTTP/2 主要有以下新的特性：

- 二进制协议
  - HTTP/2 是一个二进制协议。在 HTTP/1.1 版中，报文的头信息必须是文本（ASCII 编码），数据体可以是文本，也可以是 二进制。HTTP/2 则是一个彻底的二进制协议，头信息和数据体都是二进制，并且统称为"帧"，可以分为头信息帧和数据帧。 帧的概念是它实现多路复用的基础。

- 多路复用
  - HTTP/2 实现了多路复用，HTTP/2 仍然复用 TCP 连接，但是在一个tcp连接里，客户端和服务器都可以同时发送多个请求或回 应，而且不用按照顺序一一发送，这样就避免了"队头堵塞"的问题。
  - 并且SPDY允许给每个请求设置优先级，这样重要的请求就会先响应

- 数据流
  - HTTP/2 使用了数据流的概念，因为 HTTP/2 的数据包是不按顺序发送的，同一个连接里面连续的数据包，可能属于不同的 请求。因此，必须要对数据包做标记，指出它属于哪个请求。HTTP/2 将每个请求或回应的所有数据包，称为一个数据流。每 个数据流都有一个独一无二的编号。数据包发送的时候，都必须标记数据流 ID ，用来区分它属于哪个数据流。

- 头信息压缩

  - HTTP/2 实现了头信息压缩，由于 HTTP 1.1 协议不带有状态，每次请求都必须附上所有信息。所以，请求的很多字段都是 重复的，比如 Cookie 和 User Agent ，一模一样的内容，每次请求都必须附带，这会浪费很多带宽，也影响速度。

  - HTTP/2 对这一点做了优化，引入了头信息压缩机制。一方面，头信息使用 gzip 或 compress 压缩后再发送；另一方面， 客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引 号，这样就能提高速度了。

- 服务器推送
  - HTTP/2 允许服务器未经请求，主动向客户端发送资源，这叫做服务器推送。使用服务器推送，提前给客户端推送必要的资源 ，这样就可以相对减少一些延迟时间。这里需要注意的是 http2 下服务器主动推送的是静态资源，和 WebSocket 以及使用 SSE 等方式向客户端发送即时数据的推送是不同的。

详细的资料可以参考： [《HTTP 协议入门》](http://www.ruanyifeng.com/blog/2016/08/http.html) [《HTTP/2 服务器推送（Server Push）教程》](http://www.ruanyifeng.com/blog/2018/03/http2_server_push.html)

##### 5. HTTP/2 协议缺点

- 因为 HTTP/2 使用了多路复用，一般来说同一域名下只需要使用一个 TCP 连接。由于多个数据流使用同一个 TCP 连接，遵 守同一个流量状态控制和拥塞控制。只要一个数据流遭遇到拥塞，剩下的数据流就没法发出去，这样就导致了后面的所有数据都 会被阻塞。即虽然没有了队头阻塞的问题，还是会存在其他的阻塞问题。HTTP/2 出现的这个问题是由于其使用 TCP 协议的问题，与它本身的实现其实并没有多大关系。

##### 6. HTTP/3 协议

由于 TCP 本身存在的一些限制，Google 就开发了一个基于 UDP 协议的 QUIC 协议，并且使用在了 HTTP/3 上。 QUIC 协议在 UDP 协议上实现了多路复用、有序交付、重传等等功能

详细资料可以参考： [《如何看待 HTTP/3 ？》](https://www.zhihu.com/question/302412059)

### 1.2 HTTPS 协议

HTTP 存在的问题：

- HTTP 报文使用明文方式发送，可能被第三方窃听。

- HTTP 报文可能被第三方截取后修改通信内容，接收方没有办法发现报文内容的修改。

- HTTP 还存在认证的问题，第三方可以冒充他人参与通信。

#### 1.2.1 简介

HTTPS 指的是超文本传输安全协议，HTTPS 是基于 HTTP 协议的，不过它会使用 TLS/SSL 来对数据加密。使用 TLS/ SSL 协议，所有的信息都是加密的，第三方没有办法窃听。并且它提供了一种校验机制，信息一旦被篡改，通信的双方会立 刻发现。它还配备了身份证书，防止身份被冒充的情况出现。

#### 1.2.2 对称加密、非对称加密和数字证书：

**对称加密**：对称加密的方法是，双方使用同一个秘钥对数据进行加密和解密。但是对称加密的存在一个问题，就 是如何保证秘钥传输的安全性，因为秘钥还是会通过网络传输的，一旦秘钥被其他人获取到，那么整个加密过程就毫无作用了。 这就要用到非对称加密的方法。

**非对称加密**：每一方拥有两个秘钥，一个是公钥，一个是私钥。公钥是公开的，私钥是保密的。用私钥加密的数据，只 有对应的公钥才能解密，用公钥加密的数据，只有对应的私钥才能解密。我们可以将公钥公布出去，任何想和我们通信的客户， 都可以使用我们提供的公钥对数据进行加密，这样我们就可以使用私钥进行解密，这样就能保证数据的安全了。但是非对称加 密有一个缺点就是加密的过程很慢，因此如果每次通信都使用非对称加密的方式的话，反而会造成等待时间过长的问题。

**两者结合**：因此我们可以使用对称加密和非对称加密结合的方式，因为对称加密的方式的缺点是无法保证秘钥的安全传输，因此我们可以 非对称加密的方式来对对称加密的秘钥进行传输，然后以后的通信使用对称加密的方式来加密，这样就解决了两个方法各自存 在的问题。

**两者结合存在的问题**：但是现在的方法也不一定是安全的，因为我们没有办法确定我们得到的公钥就一定是安全的公钥。很可能我们在获取A的公钥时被C截获了，从而得到了C的公钥（得到了错误的公钥）。当我们使用他的公钥加密后发送的信息，就可以被他用自己的私钥 解密。然后他伪装成我们以同样的方法向对方发送信息，这样我们的信息就被窃取了，然而我们自己还不知道。

**数字证书**：

> 1. 在发送方A处：
>
>    ​	(1). 有公信力的认证中心（简称 CA ）先用RSA产生一对公私钥。生成一个文件P，文件中包含公钥、签发者id(CA),subject(A),有效期等信息。P属于明文信息。
>
>    ​	(2). 使用hash算法对内容P进行hash加密得到一个hash值H，然后使用签发机构的私钥对H进行RSA加密，得到签名信息S
>
>    ​	(3). 将P，S连成一个文件，这个文件就是所谓的数字证书了。
>
> 2. 在接收方B:  接收到了P和S
>
>    ​	(1). 用同样的hash算法对P进行hash计算，得到一个hash值H1
>
>    ​	(2). 用CA的公钥解密S,得到了H2
>
>    ​	(3). 对比H1和H2是否相等，如果相等，那么就证明这个证书是由签发者(CA)签发给subject(A)的证书，就是符合期望了，也就是正常情况。否则就说明：1.内容P被篡改过，或者2.证书不是由CA签发的。
>    这个是对自签发证书的验证过程。

我们使用一种 Hash 算法来对我们的公钥和其他信息进行加密生成 一个信息摘要，然后让有公信力的认证中心（简称 CA ）用它的私钥对消息摘要加密，形成签名。最后将原始的信息和签名合 在一起，称为数字证书。当接收方收到数字证书的时候，先根据原始信息使用同样的 Hash 算法生成一个摘要，然后使用公证 处的公钥来对数字证书中的摘要进行解密，最后将解密的摘要和我们生成的摘要进行对比，就能发现我们得到的信息是否被更改 了。这个方法最要的是认证中心的可靠性，一般浏览器里会内置一些顶层的认证中心的证书，相当于我们自动信任了他们，只有 这样我们才能保证数据的安全。

#### TLS 握手过程

使用数字证书：

1. 第一步，客户端A-->明文（随机数1，请求协议版本号，支持的加密方法hash)-->B

2. 第二步，服务器端B确认加密方法-->明文（选择使用的协议版本，确定的加密方法，服务器证书，随机数2）-->A

   数字证书中包含 文件P、第三方私钥(Hash(P))记为S

3. 第三步，

   A确认服务器证书有效:A用P中的公钥解密得到Hash(P)_1，用hash加密P得到Hash(P),查看Hash(P)_1=Hash(P),如果第三方截获了这个数据，修改了P，但是它没有私钥，即使可以解密S，修改后不能使用私钥加密，所以会导致结果不相等，从而被A识别到。

   A使用3个随机数和确定的加密算法计算得到协商秘钥

   A-->①使用证书公钥加密随机数3;②采用协商秘钥加密之前所有通信参数的hash值-->B

   A发送change_cipher_spec，告知B后续的通信都采用协商的通信密钥和加密算法进行加密通信

4. 第四步，服务器使用自己的私钥，来解密客户端发送过来的随机数。并提供前面所有内容的 hash 值来供客户端检验。

   B使用证书的私钥解密得到随机数3，生成协商秘钥

   计算之前所有通信参数的hash值，使用协商秘钥解密②，两者相同，则确认A的身份

   B发送change_cipher_spec，告知A后续的通信都采用协商的通信密钥和加密算法进行加密通信

   B-->协商秘钥加密所有当前的通信参数信息的hash值-->A

5. 第五步，A计算所有接收信息的hash值 === 解密得到的hash值   确认B的身份

详细资料可以参考： [《一个故事讲完 https》](https://mp.weixin.qq.com/s/StqqafHePlBkWAPQZg3NrA) [《SSL/TLS 协议运行机制的概述》](http://ruanyifeng.com/blog/2014/02/ssl_tls.html) [《图解 SSL/TLS 协议》](http://www.ruanyifeng.com/blog/2014/09/illustration-ssl.html) [《RSA 算法原理（一）》](http://www.ruanyifeng.com/blog/2013/06/rsa_algorithm_part_one.html) [《RSA 算法原理（二）》](http://www.ruanyifeng.com/blog/2013/07/rsa_algorithm_part_two.html) [《分分钟让你理解 HTTPS》](https://juejin.im/post/5ad6ad575188255c272273c4)

### 1.3 DNS 协议

DNS 协议提供的是一种主机名到 IP 地址的转换服务，就是我们常说的域名系统。它是一个由分层的 DNS 服务器组成的分 布式数据库，是定义了主机如何查询这个分布式数据库的方式的应用层协议。DNS 协议运行在 UDP 协议之上，使用 53 号 端口。

域名的层级结构可以如下

```
主机名.次级域名.顶级域名.根域名

# 即

host.sld.tld.root
```

根据域名的层级结构，管理不同层级域名的服务器，可以分为根域名服务器、顶级域名服务器和权威域名服务器。

#### 1.3.1 查询过程

www.baidu.com的DNS 的查询过程一般为：

1. 我们首先将 DNS 请求发送到本地 DNS 服务器，本地 DNS 服务器会判断是否存在该域名的缓存，存在则直接返回对应的IP地址
2. 如果不存在，那么尝试从本地计算机的 hosts文件里面去找，hosts文件中保存着本地的DNS缓存，hosts文件地址:C:\Windows\System32\drivers\etc
3. 如果还不存在，则本地域名服务器以DNS客户的身份向根域名服务器发送请求，根域名服务器返回负责 .com 的顶级域名 服务器的 IP 地址的列表。
4. 然后本地 DNS 服务器再向其中一个负责 .com 的顶级域名服务器发送请求，负责 .com 的顶级域名服务器返回负责 .baidu 的权威域名服务器的 IP 地址列表。
5. 然后本地 DNS 服务器再向其中一个权威域名服 务器发送一个请求，最后权威域名服务器返回一个对应的主机名的 IP 地址列表。
6. 本地DNS服务器将该IP地址返回给客户端，客户端发起http请求

#### 1.3.2 递归查询和迭代查询

递归查询指的是查询请求发出后，域名服务器代为向下一级域名服务器发出请求，最后向用户返回查询的最终结果。使用递归 查询，用户只需要发出一次查询请求。

迭代查询指的是查询请求后，域名服务器返回单次查询的结果。下一级的查询由用户自己请求。使用迭代查询，用户需要发出 多次的查询请求。

一般我们向本地 DNS 服务器发送请求的方式就是递归查询，因为我们只需要发出一次请求，然后本地 DNS 服务器返回给我 们最终的请求结果。而本地 DNS 服务器向其他域名服务器请求的过程是迭代查询的过程，因为每一次域名服务器只返回单次 查询的结果，下一级的查询由本地 DNS 服务器自己进行。

#### 1.3.3 DNS 缓存

DNS 缓存的原理非常简单，在一个请求链中，当某个 DNS 服务器接收到一个 DNS 回答后，它能够将回答中的信息缓存在本 地存储器中。返回的资源记录中的 TTL 代表了该条记录的缓存的时间。

#### 1.3.4 DNS 实现负载平衡

DNS 可以用于在冗余的服务器上实现负载平衡。因为现在一般的大型网站使用多台服务器提供服务，因此一个域名可能会对应多个服务器地址。当用户发起网站域名的 DNS 请求的时候，DNS 服务器返回这个域名所对应的服务器 IP 地址的集合，但在 每个回答中，会循环这些 IP 地址的顺序，用户一般会选择排在前面的地址发送请求。以此将用户的请求均衡的分配到各个不 同的服务器上，这样来实现负载均衡。

详细资料可以参考： [《DNS 原理入门》](http://www.ruanyifeng.com/blog/2016/06/dns.html) [《根域名的知识》](http://www.ruanyifeng.com/blog/2018/05/root-domain.html)

## 2 传输层

传输层协议主要是为不同主机上的不同进程间提供了逻辑通信的功能。传输层只工作在端系统中。

### 2.1 多路复用与多路分解

将传输层报文段中的数据交付到正确的套接字的工作被称为多路分解。

在源主机上从不同的套接字中收集数据，封装头信息生成报文段后，将报文段传递到网络层，这个过程被称为多路复用。

无连接的多路复用和多路分解指的是 UDP 套接字的分配过程，一个 UDP 套接字由一个二元组来标识，这个二元组包含了一 个目的地址和一个目的端口号。因此不同源地址和端口号的 UDP 报文段到达主机后，如果它们拥有相同的目的地址和目的端 口号，那么不同的报文段将会转交到同一个 UDP 套接字中。

面向连接的多路复用和多路分解指的是 TCP 套接字的分配过程，一个 TCP 套接字由一个四元组来标识，这个四元组包含了 源 IP 地址、源端口号、目的地址和目的端口号。因此，一个 TCP 报文段从网络中到达一台主机上时，该主机使用全部 4 个 值来将报文段定向到相应的套接字。

### 2.2 UDP 协议

UDP 是一种无连接的，不可靠的传输层协议。它只提供了传输层需要实现的最低限度的功能，除了复用/分解功能和少量的差 错检测外，它几乎没有对 IP 增加其他的东西。UDP 协议适用于对实时性要求高的应用场景。

特点：

1. 使用 UDP 时，在发送报文段之前，通信双方没有握手的过程，因此 UDP 被称为是无连接的传输层协议。因为没有握手 过程，相对于 TCP 来说，没有建立连接的时延。因为没有连接，所以不需要在端系统中保存连接的状态。
2. UDP 提供尽力而为的交付服务，也就是说 UDP 协议不保证数据的可靠交付。
3. UDP 没有拥塞控制和流量控制的机制，所以 UDP 报文段的发送速率没有限制。
4. 因为一个 UDP 套接字只使用目的地址和目的端口来标识，所以 UDP 可以支持一对一、一对多、多对一和多对多的交互 通信。
5. UDP 首部小，只有 8 个字节。

#### UDP 报文段结构

UDP 报文段由首部和应用数据组成。报文段首部包含四个字段，分别是源端口号、目的端口号、长度和检验和，每个字段的长 度为两个字节。长度字段指的是整个报文段的长度，包含了首部和应用数据的大小。校验和是 UDP 提供的一种差错校验机制。 虽然提供了差错校验的机制，但是 UDP 对于差错的恢复无能为力。

[![UDP 报文段结构](https://camo.githubusercontent.com/9441fdd8def46c346747b22aa93ed382b0e3f5695ab3e3f30c0468a46f3917f9/68747470733a2f2f636176737a686f75796f752d313235343039333639372e636f732e61702d63686f6e6771696e672e6d7971636c6f75642e636f6d2f6e6f74652d31362e706e67)](https://camo.githubusercontent.com/9441fdd8def46c346747b22aa93ed382b0e3f5695ab3e3f30c0468a46f3917f9/68747470733a2f2f636176737a686f75796f752d313235343039333639372e636f732e61702d63686f6e6771696e672e6d7971636c6f75642e636f6d2f6e6f74652d31362e706e67)

### 2.3 TCP 协议

TCP 协议是面向连接的，提供可靠数据传输服务的传输层协议。

特点：

1. TCP 协议是面向连接的，在通信双方进行通信前，需要通过三次握手建立连接。它需要在端系统中维护双方连接的状态信息。
2. TCP 协议通过序号、确认号、定时重传、检验和等机制，来提供可靠的数据传输服务。
3. TCP 协议提供的是点对点的服务，即它是在单个发送方和单个接收方之间的连接。
4. TCP 协议提供的是全双工的服务，也就是说连接的双方的能够向对方发送和接收数据。
5. TCP 提供了拥塞控制机制，在网络拥塞的时候会控制发送数据的速率，有助于减少数据包的丢失和减轻网络中的拥塞程度。
6. TCP 提供了流量控制机制，保证了通信双方的发送和接收速率相同。如果接收方可接收的缓存很小时，发送方会降低发送 速率，避免因为缓存填满而造成的数据包的丢失。

#### 2.3.1 TCP 报文段结构

TCP传送的数据单位是报文段，一个TCP报文段分为首部和数据两部分，TCP的全部功能都体现在它首部中各字段的作用
下面将TCP的首部展开：前20字节是固定的，故TCP首部最小长度是20字节

![](E:\workspaces\note\http交互\medias\1.png)

```
序号seq：占4个字节，用来标记数据段的顺序，TCP把连接中发送的所有数据字节都编上一个序号，第一个字节的编号由本地随机产生；序号字段值seq就是这个报文段中的第一个字节的数据编号。
	例如一段报文的序号是301，而携带的数据共有100字节，则表示：本报文段的第一个字节的数据序号是301,最后一个字节序号为400，下一个报文段的数据序号应该从401开始，即下个报文段的序号字段值应该为401

确认号ack：占4个字节，期待收到对方下一个报文段的第一个数据字节的序号；确认号指的是期望接收到下一个字节的编号；因此当前报文段最后一个字节的编号+1即为确认号。若确认号为N，则表示到序号N-1为止的所有数据都已正确收到。
	例如：B正确收到了A发送过来的一个报文段，其序号字段为500，而数据长度为200，则表明B正确收到了A发送的到序号700为止的数据，因此，B期望收到的下一个数据序号是701，于是B在给A发送的确认报文中将确认号ack置为701。

确认ACK：占1位，仅当ACK=1时，确认号字段ack才有效。ACK=0时，确认号字段无效

同步SYN：连接建立时用于同步序号。当SYN=1，ACK=0时表示：这是一个连接请求报文段。若同意连接，则在响应报文段中使得SYN=1，ACK=1。因此，SYN=1表示这是一个连接请求报文。SYN这个标志位只有在TCP建产连接时才会被置1，握手完成后SYN标志位被置0。

终止FIN：用来释放一个连接。FIN=1表示：此报文段的发送方的数据已经发送完毕，并要求释放运输连接

PS：ACK、SYN和FIN这些大写的单词表示标志位，其值要么是1，要么是0；ack、seq小写的单词表示序号。
```

#### 2.3.2 TCP 三次握手

![](.\medias\2.png)

```
客户端A主动打开连接，服务器端B被动打开连接

B的TCP服务器进程先创建传输控制块TCB，准备接受客户进程的连接请求，然后服务器进程处于LISTEN状态，等待客户端发送请求

A的TCP客户进程创建传输控制模块TCB

第一次握手：建立连接时，客户端A发送连接请求报文段（SYN=1，选择初始序号syn=x）到服务器，并进入SYN_SENT（同步已发送）状态，等待服务器确认；
	TCP规定，SYN报文段(即SYN=1的报文段)不能携带数据，但是要消耗掉一个序号
	所以第二次握手中的确认报文的确认号ack=x+1

第二次握手：服务器B收到客户端A的连接请求报文段，如果同意连接，则必须发送确认报文段（SYN=1,ACK=1,ack=x+1，选择初始序号seq=y），此时服务器进入SYN_RECV（同步收到）状态；

第三次握手：客户端A收到服务器B的确认报文段，向服务器发送ACK确认报文段(ACK=1,seq=x+1,ack=y+1），此包发送完毕，客户端和服务器进入ESTABLISHED（TCP连接成功）状态，完成三次握手。
	TCP规定，ACK报文可以携带数据，所以如果B发给A的ACK报文中携带了M字节的数据，则第三次握手时ack=y+M+1
```

相关问题：

```
1 为什么A还要再次确认呢？第三次握手存在的意义
	主要是为了防止已经失效的连接请求报文段突然又传给了B，造成B的资源浪费
	解释：
		假定两次握手就可以建立TCP连接
		假设A先发送了一个连接请求1，但是该请求在某些网络结点长时间滞留了。
		于是A又重新发起了连接请求2，并且请求2得到了确认，A、B之间建立了连接，两者传输数据结束并且释放了连接之后的一段时间，请求1到达了B，则B会以为A又发起了一次新的请求，就会发送确认报文，则两者之间的连接就建立了。但是此时A并不会理睬B的确认，也不会向B发送数据，B却一直在等待A发送数据，就导致了B资源的浪费。
		使用三次握手，则A收到B的确认报文后，A不会向B发送确认报文，则B由于收不到确认报文，就知道A没有请求建立连接
```

#### 2.3.3 TCP 四次挥手的过程

![](.\medias\3.png)

```
第一次挥手：A发送释放连接请求，A进入终止等待1状态
1）客户端进程A发出连接释放报文FIN，并且停止发送数据。将释放报文首部的FIN置为1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时，客户端A进入FIN-WAIT-1（终止等待1）状态。 
	TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。

第二次挥手：B确认收到了A释放连接的请求，B进入关闭等待状态，但是B还可以发送数据给A
2）服务器B收到连接释放报文，发出确认报文FIN+ACK，ACK=1，ack=u+1，选择序列号seq=v，此时，服务端就进入了CLOSE-WAIT（关闭等待）状态。
	TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。
	这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。

3）客户端A收到服务器B的确认请求后，此时，客户端A就进入FIN-WAIT-2（终止等待2）状态，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。

第三次挥手：B传输完了数据，发送释放连接报文，进入最后确认的状态
4）服务器将最后的数据发送完毕后，就向客户端发送连接释放报文FIN，FIN=1，ack=u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。

第四次挥手：A收到释放连接报文，发出确认收到释放连接的报文，进入时间等待状态
5）客户端收到服务器的连接释放报文后，必须发出确认报文FIN+ACK，ACK=1，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态。注意此时TCP连接还没有释放，必须经过2MSL（最长报文段寿命）的时间后，当客户端撤销相应的TCB后，才进入CLOSED状态。
	MSL是由TCP的时间等待计时器设置的，叫做最长报文段寿命

6）服务器只要收到了客户端发出的释放连接确认，立即进入CLOSED状态。同样，撤销TCB后，就结束了这次的TCP连接。可以看到，服务器结束TCP连接的时间要比客户端早一些。
```

相关问题：

```
1 A为什么要等待2MSL的时间才能进入关闭状态呢？
	（1）为了保证B收到了A第四次挥手时发送的FIN+ACK报文
		这个报文很有可能丢失，从而导致处于最后确认状态的B收不到，B就会超时重传FIN报文，而A就可以在2MSL时间内收到FIN报文，并且再次发送确认报文FIN+ACK，这样B就可以完成释放连接，否则B收不到就无法释放连接进入CLOSED状态
	（2）防止已失效的报文请求连接

2 如果已经建立连接，但是客户端A出现故障，如何传输数据呢？
	除了时间等待计时器，TCP还设有一个保活计时器
	服务器每次收到一次客户端的数据，就会重新设置保活计时器，通常设置两个小时，若两小时内没有收到A发送的数据，则服务器就发送一个探测报文段，以后每隔75s发送一次，若一连发送10个探测报文段后A仍无响应，则服务器就认为iA出现了故障，然后就关闭两者之间的连接。
	
3 为什么连接的时候是三次握手，关闭的时候却是四次握手？
	因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，"你发的FIN报文我收到了"。只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。
```

参考：[TCP的三次握手与四次挥手理解及面试题（很全面）](https://blog.csdn.net/qq_38950316/article/details/81087809)

#### 状态转化图

[![客户端状态图](https://camo.githubusercontent.com/254c02606682ce2d08b801e9f867bd7cdacfcd975a33ab06bbf76100d15adeb6/68747470733a2f2f636176737a686f75796f752d313235343039333639372e636f732e61702d63686f6e6771696e672e6d7971636c6f75642e636f6d2f6e6f74652d31382e706e67)](https://camo.githubusercontent.com/254c02606682ce2d08b801e9f867bd7cdacfcd975a33ab06bbf76100d15adeb6/68747470733a2f2f636176737a686f75796f752d313235343039333639372e636f732e61702d63686f6e6771696e672e6d7971636c6f75642e636f6d2f6e6f74652d31382e706e67)

[![服务端状态图](https://camo.githubusercontent.com/3e98d73fafa242cea7efa898d43a096a3ab44801188fba251d75d3abc61dbe8d/68747470733a2f2f636176737a686f75796f752d313235343039333639372e636f732e61702d63686f6e6771696e672e6d7971636c6f75642e636f6d2f6e6f74652d31392e706e67)](https://camo.githubusercontent.com/3e98d73fafa242cea7efa898d43a096a3ab44801188fba251d75d3abc61dbe8d/68747470733a2f2f636176737a686f75796f752d313235343039333639372e636f732e61702d63686f6e6771696e672e6d7971636c6f75642e636f6d2f6e6f74652d31392e706e67)

#### 2.3.4 ARQ 协议

ARQ 协议:Automatic Repeat-reQuest,指的是自动重传请求，它通过超时和重传来保证数据的可靠交付，它是 TCP 协议实现可靠数据传输的一个很重要的 机制。

它分为停止等待 ARQ 协议和连续 ARQ 协议。

**1. 停止等待 ARQ 协议**:

停止等待 ARQ 协议的基本原理是，对于发送方来说发送方每发送一个分组，就为这个分组设置一个定时器。当发送分组的确认回答返回了，则清除定时器，发送下一个分组。如果在规定的时间内没有收到已发送分组的肯定回答，则重新发送上一个分组。

对于接受方来说，每次接受到一个分组，就返回对这个分组的肯定应答，当收到冗余的分组时，就直接丢弃，并返回一个对冗余分组的确认。当收到分组损坏的情况的时候，直接丢弃。

使用停止等待 ARQ 协议的缺点是**每次发送分组必须等到分组确认后才能发送下一个分组**，这样会造成信道的利用率过低。

**2. 连续 ARQ 协议**:

连续 ARQ 协议是为了解决停止等待 ARQ 协议对于信道的利用率过低的问题。它通过**连续发送一组分组**，然后再等待对分组的 确认回答，对于如何处理分组中可能出现的差错恢复情况，一般可以使用**滑动窗口协议和选择重传协议**来实现。

1. 滑动窗口协议

   ​		使用滑动窗口协议，在发送方维持了一个发送窗口，发送窗口以前的分组是已经发送并确认了的分组，发送窗口中包含了已经发 送但未确认的分组和允许发送但还未发送的分组，发送窗口以后的分组是缓存中还不允许发送的分组。当发送方向接收方发送分 组时，会依次发送窗口内的所有分组，并且设置一个定时器，这个定时器可以理解为是最早发送但未收到确认的分组。如果在定 时器的时间内收到某一个分组的确认回答，则滑动窗口，将窗口的首部移动到确认分组的后一个位置，此时如果还有已发送但没 有确认的分组，则重新设置定时器，如果没有了则关闭定时器。如果定时器超时，则重新发送所有已经发送但还未收到确认的分 组。

   注意：比如发送窗口4 5 6 7，发送所有分组后，设置定时器，收到了4的确认，则发送窗口移动到5 6 7 8，重置定时器，5收到确认，发送窗口移动到6 7 8 9，重置定时器，如果定时器超时候仍未收到确认，则重新发送 发送窗口中的所有分组

   ​		接收方使用的是累计确认的机制，对于所有按序到达的分组，接收方返回一个分组的肯定回答。**如果收到了一个乱序的分组，那 么接方会直接丢弃，并返回一个最近的按序到达的分组的肯定回答。**使用累计确认保证了确认号以前的分组都已经按序到达了， 所以发送窗口可以移动到已确认分组的后面。

   ​		滑动窗口协议的缺点是因为使用了累计确认的机制，如果出现了只是窗口中的第一个分组丢失，而后面的分组都按序到达的情况 的话，那么滑动窗口协议会重新发送所有的分组，这样就造成了大量不必要分组的丢弃和重传。

2. 选择重传协议

   因为滑动窗口使用累计确认的方式，所以会造成很多不必要分组的重传。使用选择重传协议可以解决这个问题。

​		选择重传协议在发送方维护了一个发送窗口。发送窗口的以前是已经发送并确认的分组，窗口内包含了已发送但未被确认的分组， 已确认的乱序分组，和允许发送但还未发送的分组，发送窗口以后的是缓存中还不允许发送的分组。选择重传协议与滑动窗口协 议最大的不同是，发送方发送分组时，为一个分组都创建了一个定时器。当发送方接受到一个分组的确认应答后，取消该分组的 定时器，并判断接受该分组后，是否存在由窗口首部为首的连续的确认分组，如果有则向后移动窗口的位置，如果没有则将该分 组标识为已接收的乱序分组。当某一个分组定时器到时后，则重新传递这个分组。

​		**在接收方，它会确认每一个正确接收的分组，不管这个分组是按序的还是乱序的，乱序的分组将被缓存下来，直到所有的乱序分 组都到达形成一个有序序列后，再将这一段分组交付给上层。**对于不能被正确接收的分组，接收方直接忽略该分组。

详细资料可以参考： [《TCP 连续 ARQ 协议和滑动窗口协议》](https://blog.csdn.net/guoweimelon/article/details/50879588)

#### 2.3.5 TCP 的可靠运输机制

**TCP 的可靠运输机制是基于连续 ARQ 协议和滑动窗口协议的**。

​		TCP 协议在发送方维持了一个发送窗口，发送窗口以前的报文段是已经发送并确认了的报文段，发送窗口中包含了已经发送但 未确认的报文段和允许发送但还未发送的报文段，发送窗口以后的报文段是缓存中还不允许发送的报文段。当发送方向接收方发 送报文时，会依次发送窗口内的所有报文段，并且设置一个定时器，这个定时器可以理解为是最早发送但未收到确认的报文段。 如果在定时器的时间内收到某一个报文段的确认回答，则滑动窗口，将窗口的首部向后滑动到确认报文段的后一个位置，此时如 果还有已发送但没有确认的报文段，则重新设置定时器，如果没有了则关闭定时器。如果定时器超时，则重新发送所有已经发送 但还未收到确认的报文段，并将超时的间隔设置为以前的两倍。当发送方收到接收方的三个冗余的确认应答后，这是一种指示， 说明该报文段以后的报文段很有可能发生丢失了，那么发送方会启用快速重传的机制，就是当前定时器结束前，发送所有的已发 送但确认的报文段。

接收方使用的是累计确认的机制，对于所有按序到达的报文段，接收方返回一个报文段的肯定回答。如果收到了一个乱序的报文 段，那么接方会直接丢弃，并返回一个最近的按序到达的报文段的肯定回答。使用累计确认保证了返回的确认号之前的报文段都 已经按序到达了，所以发送窗口可以移动到已确认报文段的后面。

发送窗口的大小是变化的，它是由接收窗口剩余大小和网络中拥塞程度来决定的，TCP 就是通过控制发送窗口的长度来控制报文 段的发送速率。

但是 TCP 协议并不完全和滑动窗口协议相同，因为许多的 TCP 实现会将失序的报文段给缓存起来，并且发生重传时，只会重 传一个报文段，因此 TCP 协议的可靠传输机制更像是窗口滑动协议和选择重传协议的一个混合体。

#### 2.3.6 TCP 的流量控制机制

​		TCP 提供了流量控制的服务，这个服务的主要目的是控制发送方的发送速率，保证接收方来得及接收。因为一旦发送的速率大 于接收方所能接收的速率，就会造成报文段的丢失。接收方主要是通过**接收窗口**来告诉发送方自己所能接收的大小，**发送方根据 接收方的接收窗口的大小来调整发送窗口的大小**，以此来达到控制发送速率的目的。

#### 2.3.7 TCP 的拥塞控制机制

​		TCP 的拥塞控制主要是根据网络中的拥塞情况来控制发送方数据的发送速率，如果网络处于拥塞的状态，发送方就减小发送的 速率，这样一方面是为了避免继续增加网络中的拥塞程度，另一方面也是为了避免网络拥塞可能造成的报文段丢失。

TCP 的拥塞控制主要使用了四个机制，分别是**慢启动、拥塞避免、快速重传和快速恢复**。

- 慢启动的基本思想是，因为在发送方刚开始发送数据的时候，并不知道网络中的拥塞程度，所以先以较低的速率发送，从1开始，设定一个慢开始门限ssthreh。每次收到一个确认报文，就将发动窗口的长度加倍，这样每个 RTT 时间后，发送窗口的长度就会加倍。当发送窗口的大小达 到门限值的时候就进入拥塞避免算法。

- 拥塞避免算法是为了避免可能发生的拥塞，将发送窗口的大小由每过一个 RTT 增长一倍，变为每过一个 RTT ，长度只加一。 这样将窗口的增长速率由指数增长，变为加法线性增长。当网络出现超时，则将门限ssthreh调整为超时时拥塞窗口的一半，发送窗口置为1，重新慢开始。

- 快速重传指的是，当发送方收到三个冗余的确认应答时，因为 TCP 使用的是累计确认的机制，所以很有可能是发生了报文段的 丢失，因此采用立即重传的机制，在定时器结束前发送所有已发送但还未接收到确认应答的报文段。

- 快速恢复是对快速重传的后续处理，因为网络中可能已经出现了拥塞情况，所以会将慢启动的阀值ssthreh减小为原来的一半，然后将发送窗口的值置为减半后的阀值，然后开始执行拥塞避免算法，使得拥塞窗口缓慢地加性增大。简单来理解就是，乘性减，加性增。

TCP 认为网络拥塞的主要依据是报文段的重传次数，它会根据网络中的拥塞程度，通过调整慢启动的阀值，然后交替使用上面四 种机制来达到拥塞控制的目的。

详细资料可以参考： [《TCP 的拥塞控制机制》](https://www.jianshu.com/p/7d59f9292b03) [《网络基本功：TCP 拥塞控制机制》](http://www.voidcn.com/article/p-vrdkquop-ms.html)

## 3 网络层

网络层协议主要实现了不同主机间的逻辑通信功能。网络层协议一共包含两个主要的组件，一个 IP 网际协议，一个是路由选 择协议。

IP 网际协议规定了网络层的编址和转发方式，比如说我们接入网络的主机都会被分配一个 IP 地址，常用的比如 IPV4 使用 32 位来分配地址，还有 IPv6 使用 128 位来分配地址。

路由选择协议决定了数据报从源到目的地所流经的路径，常见的比如距离向量路由选择算法等。

## 4 数据链路层

数据链路层提供的服务是如何将数据报通过单一通信链路从一个结点移动到相邻节点。每一台主机都有一个唯一的 MAC 地址， 这是由网络适配器决定的，在全世界都是独一无二的。

## 5 物理层

物理层提供的服务是尽可能的屏蔽掉组成网络的物理设备和传输介质间的差异，使数据链路层不需要考虑网络的具体传输介质 是什么。

详细资料可以参考： [《搞定计算机网络面试，看这篇就够了（补充版）》](https://juejin.im/post/5b7be0b2e51d4538db34a51e#heading-1) [《互联网协议入门（一）》](http://www.ruanyifeng.com/blog/2012/05/internet_protocol_suite_part_i.html) [《互联网协议入门（二）》](http://www.ruanyifeng.com/blog/2012/06/internet_protocol_suite_part_ii.html)

## 6 常考面试题

#### 1. Post 和 Get 的区别？

```
Post 和 Get 是 HTTP 请求的两种方法。

（1）从应用场景上来说，GET 请求是一个幂等的请求，一般 Get 请求用于对服务器资源不会产生影响的场景，比如说请求一个网
页。而 Post 不是一个幂等的请求，一般用于对服务器资源会产生影响的情景。比如注册用户这一类的操作。

（2）因为不同的应用场景，所以浏览器一般会对 Get 请求缓存，但很少对 Post 请求缓存。

（3）从发送的报文格式来说，Get 请求的报文中实体部分为空，Post 请求的报文中实体部分一般为向服务器发送的数据。

（4）但是 Get 请求也可以将请求的参数放入 url 中向服务器发送，这样的做法相对于 Post 请求来说，一个方面是不太安全，
因为请求的 url 会被保留在历史记录中。并且浏览器由于对 url 有一个长度上的限制，所以会影响 get 请求发送数据时
的长度。这个限制是浏览器规定的，并不是 RFC 规定的。还有就是 post 的参数传递支持更多的数据类型。
```

#### 2. TLS/SSL 中什么一定要用三个随机数，来生成"会话密钥"？

TLS:Transport Layer Secure

SSL:Secure Socket Layer

```
客户端和服务器都需要生成随机数，以此来保证每次生成的秘钥都不相同。

使用三个随机数，是因为 SSL 的协议不信任每个主机都能产生完全随机的数，所以需要客户端和服务器端都产生一个随机数。另外，由于SSL协议中证书是静态的，因此十分有必要引入一种随机因素来保证协商出来的密钥的随机性。

如果只使用一个伪随机的数来生成秘钥，就很容易被破解。通过使用三个随机数的方式，增加了自由度，一个伪随机可能被破解，但是三个伪随机就很接近于随机了，因此可以使用这种方法来保持生成秘钥的随机性和安全性。

个人理解：前两个随机数是明文传输的，可能被第三方截获到，后一个随机数是加密传输的，比较安全。而三个随机数产生秘钥，自由度增加。
```

#### 3. SSL 连接断开后如何恢复？

```
一共有两种方法来恢复断开的 SSL 连接，一种是使用 session ID，一种是 session ticket。

seesionID:

tcp握手阶段：客户端->(session ID,其他信息)->服务器端，服务器端查看sessionID为空，则进行完整的tcp连接，生成新的sessionID发送给客户端，客户端和服务器端均会保存该sessionID；否则将该sessionID与服务器缓存中的sessionID进行匹配，匹配到则直接进行http通话即可，无需进行tcp握手了。

使用 session ID 的方式，服务器端保存会话信息，每一次的会话都有一个编号，当对话中断后，下一次重新连接时，只要客户端给出这个编号，服务器如果有这个编号的记录，那么双方就可以继续使用以前的秘钥，而不用重新生成一把。目前所有的浏览器都支持这一种方法。但是这种方法有一个缺点是，session ID 只能够存在一台服务器上，如果我们的请求通过负载平衡(大型应用可能会使用多个服务器，即一个域名对应了多个IP地址)被转移到了其他的服务器上，那么就无法恢复对话。

sessionTicket:

另一种方式是 session ticket 的方式客户端和服务器端建立了一次完整的握手过程后，服务器端将本次的会话数据进行加密，例如前面说到的，会话标识符、证书、密码套件和主密钥等，加密后生成一个ticket票据，并将票据通过NewSessionTicket子消息发送给客户端，由客户端来保存，下一次连接时客户端如果希望恢复上一次会话而不是重新进行握手，就将“票据”一起发送给服务器端，待服务器端解密校验无误后，进行一次简短的握手，恢复上一次会话。
```

[(8条消息) Session会话恢复：两种简短的握手总结SessionID&SessionTicket_大力海棠的博客-CSDN博客](https://blog.csdn.net/justinzengTM/article/details/105491809)

#### 4. RSA加密算法的安全性保障？

```
对极大整数做因数分解的难度决定了 RSA 算法的可靠性。

换言之，对一极大整数做因数分解愈困难，RSA 算法愈可靠。现在1024位的 RSA 密钥基本安全，2048位的密钥极其安全。
```

#### 5. DNS 为什么使用 UDP 协议作为传输层协议？

```
DNS 使用 UDP 协议作为传输层协议的主要原因是为了避免使用 TCP 协议时造成的连接时延。因为为了得到一个域名的 IP 地址，往往会向多个域名服务器查询，如果使用 TCP 协议，那么每次请求都会存在连接时延，这样使 DNS 服务变得很慢，因为大多数的地址查询请求，都是浏览器请求页面时发出的，这样会造成网页的等待时间过长。

使用 UDP 协议作为 DNS 协议会有一个问题，由于历史原因，物理链路的最小MTU = 576，所以为了限制报文长度不超过576，UDP 的报文段的长度被限制在 512 个字节以内，这样一旦 DNS 的查询或者应答报文，超过了 512 字节，那么基于 UDP 的DNS 协议就会被截断为 512 字节，那么有可能用户得到的 DNS 应答就是不完整的。这里 DNS 报文的长度一旦超过限制，并不会像 TCP 协议那样被拆分成多个报文段传输，因为 UDP 协议不会维护连接状态，所以我们没有办法确定那几个报文段属于同一个数据，UDP 只会将多余的数据给截取掉。为了解决这个问题，我们可以使用 TCP 协议去请求报文。

DNS 还存在的一个问题是安全问题，就是我们没有办法确定我们得到的应答，一定是一个安全的应答，因为应答可以被他人伪造，所以现在有了 DNS over HTTPS 来解决这个问题。
```

详细资料可以参考： [《为什么 DNS 使用 UDP 而不是 TCP？》](https://www.zhihu.com/question/310145373)

#### 6. 当你在浏览器中输入 Google.com 并且按下回车之后发生了什么？

```
（1）首先会对 URL 进行解析，分析所需要使用的传输协议和请求的资源的路径。如果输入的 URL 中的协议或者主机名不合法，将会把地址栏中输入的内容传递给搜索引擎。如果没有问题，浏览器会检查 URL 中是否出现了非法字符，如果存在非法字符，则对非法字符进行转义后再进行下一过程。

（2）浏览器会判断所请求的资源是否在缓存里，如果请求的资源在缓存里并且没有失效，那么就直接使用，否则向服务器发起新的请求。

（3）下一步我们首先需要获取的是输入的 URL 中的域名的 IP 地址，首先会判断本地是否有该域名的 IP 地址的缓存，如果有则使用，如果没有则向本地 DNS 服务器发起请求。本地 DNS 服务器也会先检查是否存在缓存，如果没有就会先向根域名服务器发起请求，获得负责的顶级域名服务器的地址后，再向顶级域名服务器请求，然后获得负责的权威域名服务器的地址后，再向权威域名服务器发起请求，最终获得域名的 IP 地址后，本地 DNS 服务器再将这个 IP 地址返回给请求的用户。用户向本地 DNS 服务器发起请求属于递归请求，本地 DNS 服务器向各级域名服务器发起请求属于迭代请求。

（4）当浏览器得到 IP 地址后，数据传输还需要知道目的主机 MAC 地址，因为应用层下发数据给传输层，TCP 协议会指定源端口号和目的端口号，然后下发给网络层。网络层会将本机地址作为源地址，获取的 IP 地址作为目的地址。然后将下发给数据链路层，数据链路层的发送需要加入通信双方的 MAC 地址，我们本机的 MAC 地址作为源 MAC 地址，目的 MAC 地址需要分情况处理，通过将 IP 地址与我们本机的子网掩码相与，我们可以判断我们是否与请求主机在同一个子网里，如果在同一个子网里，我们可以使用 APR 协议获取到目的主机的 MAC 地址，如果我们不在一个子网里，那么我们的请求应该转发给我们的网关，由它代为转发，此时同样可以通过 ARP 协议来获取网关的 MAC 地址，此时目的主机的 MAC 地址应该为网关的地址。

（5）下面是 TCP 建立连接的三次握手的过程，首先客户端向服务器发送一个 SYN 连接请求报文段和一个随机序号，服务端接收到请求后向服务器端发送一个 SYN ACK报文段，确认连接请求，并且也向客户端发送一个随机序号。客户端接收服务器的确认应答后，进入连接建立的状态，同时向服务器也发送一个 ACK 确认报文段，服务器端接收到确认后，也进入连接建立状态，此时双方的连接就建立起来了。

（6）如果使用的是 HTTPS 协议，在通信前还存在 TLS 的一个四次握手的过程。首先由客户端向服务器端发送使用的协议的版本号、一个随机数和可以使用的加密方法。服务器端收到后，确认加密的方法，也向客户端发送一个随机数和自己的数字证书。客户端收到后，首先检查数字证书是否有效，如果有效，则再生成一个随机数，并使用证书中的公钥对随机数加密，然后发送给服务器端，并且还会提供一个前面所有内容的 hash 值供服务器端检验。服务器端接收后，使用自己的私钥对数据解密，同时向客户端发送一个前面所有内容的 hash 值供客户端检验。这个时候双方都有了三个随机数，按照之前所约定的加密方法，使用这三个随机数生成一把秘钥，以后双方通信前，就使用这个秘钥对数据进行加密后再传输。

（7）当页面请求发送到服务器端后，服务器端会返回一个 html 文件作为响应，浏览器接收到响应后，开始对 html 文件进行解析，开始页面的渲染过程。

（8）浏览器首先会根据 html 文件构建 DOM 树，根据解析到的 css 文件构建 CSSOM 树，如果遇到 script 标签，则判端是否含有 defer 或者 async 属性，要不然 script 的加载和执行会造成页面的渲染的阻塞。当 DOM 树和 CSSOM 树建立好后，根据它们来构建渲染树。渲染树构建好后，会根据渲染树来进行布局。布局完成后，最后使用浏览器的 UI 接口对页面进行绘制。这个时候整个页面就显示出来了。

（9）最后一步是 TCP 断开连接的四次挥手过程。
```

详细资料可以参考： [《当你在浏览器中输入 Google.com 并且按下回车之后发生了什么？》](http://blog.jobbole.com/84870/)

#### 7. 谈谈 CDN 服务？

CDN : Content Delivery Network  内容分发网络

```
CDN 是一个内容分发网络，通过对源网站资源的缓存，利用本身多台位于不同地域、不同运营商的服务器，向用户提供资就近访问的功能。也就是说，用户的请求并不是直接发送给源网站，而是发送给 CDN 服务器，由 CND 服务器将请求定位到最近的含有该资源的服务器上去请求。

这样有利于提高网站的访问速度，同时通过这种方式也减轻了源服务器的访问压力。
```

详细资料可以参考： [《CDN 是什么？使用 CDN 有什么优势？》](https://www.zhihu.com/question/36514327?rf=37353035)

#### 8. 什么是正向代理和反向代理？

```
我们常说的代理也就是指正向代理，正向代理的过程，它隐藏了真实的请求客户端，服务端不知道真实的客户端是谁，客户端请求的服务都被代理服务器代替来请求。

反向代理隐藏了真实的服务器端，当我们请求一个网站的时候，背后可能有成千上万台服务器为我们服务，但具体是哪一台，我们不知道，也不需要知道，我们只需要知道反向代理服务器是谁就好了，反向代理服务器会帮我们把请求转发到真实的服务器那里去。反向代理器一般用来实现负载平衡。
```

详细资料可以参考： [《正向代理与反向代理有什么区别》](https://mp.weixin.qq.com/s/ikrI3rmSYs83wdSWqq2QIg?) [《webpack 配置 proxy 反向代理的原理是什么？》](https://segmentfault.com/q/1010000017502539/a-1020000017532348)

#### 9. 负载平衡的两种实现方式？

```
一种是使用反向代理的方式，用户的请求都发送到反向代理服务上，然后由反向代理服务器来转发请求到真实的服务器上，以此来实现集群的负载平衡。

另一种是 DNS 的方式，DNS 可以用于在冗余的服务器上实现负载平衡。因为现在一般的大型网站使用多台服务器提供服务，因此一个域名可能会对应多个服务器地址。当用户向网站域名请求的时候，DNS 服务器返回这个域名所对应的服务器 IP 地址的集合，但在每个回答中，会循环这些 IP 地址的顺序，用户一般会选择排在前面的地址发送请求。以此将用户的请求均衡的分配到各个不同的服务器上，这样来实现负载均衡。这种方式有一个缺点就是，由于 DNS 服务器中存在缓存，所以有可能一个服务器出现故障后，域名解析仍然返回的是那个 IP 地址，就会造成访问的问题。
```

详细资料可以参考： [《负载均衡的原理》](https://mp.weixin.qq.com/s?__biz=MzA5Njc2OTg4NQ==&mid=2247483870&idx=1&sn=bab36544ec62c394c104df699cf85154&chksm=90aa43eca7ddcafa01634cefee12fd8a332250d3f49d8b6647f536c215ac297e4b6a53af8253#rd)

#### 10. http 请求方法 options 方法有什么用？

```
OPTIONS 请求与 HEAD 类似，一般也是用于客户端查看服务器的性能。这个方法会请求服务器返回该资源所支持的所有 HTTP 请求方法，该方法会用'*'来代替资源名称，向服务器发送 OPTIONS 请求，可以测试服务器功能是否正常。

JS 的 XMLHttpRequest对象进行 CORS 跨域资源共享时，对于复杂请求，就是使用 OPTIONS 方法发送嗅探请求，以判断是否有对指定资源的访问权限。
```

相关资料可以参考： [《HTTP 请求方法》](https://itbilu.com/other/relate/EkwKysXIl.html)

#### 12. 网站域名加 www 与不加 www 的区别？

详细资料可以参考： [《为什么域名前要加 www 前缀 www 是什么意思？》](https://www.f9seo.com/post-816.html) [《为什么越来越多的网站域名不加「www」前缀？》](https://www.zhihu.com/question/20414602) [《域名有 www 与没有 www 有什么区别？》](https://blog.csdn.net/andybruse/article/details/7982278)

#### 13. 即时通讯的实现，短轮询、长轮询、SSE 和 WebSocket 间的区别？

```
短轮询和长轮询的目的都是用于实现客户端和服务器端的一个即时通讯。

短轮询的基本思路就是浏览器每隔一段时间向服务器发送 http 请求，服务器端在收到请求后，不论是否有数据更新，都直接进行响应。这种方式实现的即时通信，本质上还是浏览器发送请求，服务器接受请求的一个过程，通过让客户端不断的进行请求，使得客户端能够模拟实时地收到服务器端的数据的变化。这种方式的优点是比较简单，易于理解。缺点是这种方式由于需要不断的建立 http 连接，严重浪费了服务器端和客户端的资源。当用户增加时，服务器端的压力就会变大，这是很不合理的。

长轮询的基本思路是，首先由客户端向服务器发起请求，当服务器收到客户端发来的请求后，服务器端不会直接进行响应，而是先将这个请求挂起，然后判断服务器端数据是否有更新。如果有更新，则进行响应，如果一直没有数据，则到达一定的时间限制才返回。客户端 JavaScript 响应处理函数会在处理完服务器返回的信息后，再次发出请求，重新建立连接。长轮询和短轮询比起来，它的优点是明显减少了很多不必要的 http 请求次数，相比之下节约了资源。长轮询的缺点在于，连接挂起也会导致资源的浪费。

SSE 的基本思想是，服务器使用流信息向服务器推送信息。严格地说，http 协议无法做到服务器主动推送信息。但是，有一种变通方法，就是服务器向客户端声明，接下来要发送的是流信息。也就是说，发送的不是一次性的数据包，而是一个数据流，会连续不断地发送过来。这时，客户端不会关闭连接，会一直等着服务器发过来的新的数据流，视频播放就是这样的例子。SSE 就是利用这种机制，使用流信息向浏览器推送信息。它基于 http 协议，目前除了 IE/Edge，其他浏览器都支持。它相对于前面两种方式来说，不需要建立过多的 http 请求，相比之下节约了资源。

上面三种方式本质上都是基于 http 协议的，我们还可以使用 WebSocket 协议来实现。WebSocket 是 Html5 定义的一个新协议，与传统的 http 协议不同，该协议允许由服务器主动的向客户端推送信息。使用 WebSocket 协议的缺点是在服务器端的配置比较复杂。WebSocket 是一个全双工的协议，也就是通信双方是平等的，可以相互发送消息，而 SSE 的方式是单向通信的，只能由服务器端向客户端推送信息，如果客户端需要发送信息就是属于下一个 http 请求了。
```

详细资料可以参考： [《轮询、长轮询、长连接、websocket》](https://cloud.tencent.com/developer/article/1076547) [《Server-Sent Events 教程》](http://www.ruanyifeng.com/blog/2017/05/server-sent_events.html) [《WebSocket 教程》](http://www.ruanyifeng.com/blog/2017/05/websocket.html)

#### 14. 怎么实现多个网站之间共享登录状态

```
在多个网站之间共享登录状态指的就是单点登录。多个应用系统中，用户只需要登录一次就可以访问所有相互信任的应用系统。

我认为单点登录可以这样来实现：
1. 首先将用户信息的验证中心独立出来，作为一个单独的认证中心，该认证中心的作用是判断客户端发送的账号密码的正确性，然后向客户端返回对应的用户信息，并且返回一个由服务器端秘钥加密的登录信息的token给客户端，该token 具有一定的有效时限。
2. 当一个应用系统跳转到另一个应用系统时，通过 url 参数的方式来传递token，然后转移到的应用站点发送给认证中心，认证中心对 token 进行解密后验证，如果用户信息没有失效，则向客户端返回对应的用户信息，如果失效了则将页面重定向会单点登录页面。
```

详细资料可以参考： [《HTTP 是个无状态协议，怎么保持登录状态？》](https://www.zhihu.com/question/35906139)